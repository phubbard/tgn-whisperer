# For each episode, we download the MP3, for local hosting, and then call out to WhisperX.
# Once that's done, we convert the output to markdown and deploy it to the site.
# Made much simpler by having a JSON config file (fields extracted via jq) and
# fixed filenames for each step of the process.
# The jq output results in embedded quote characters, so we need two steps. Three, to cache the jq step.
dest_dir:=$(shell cat episode.json | jq .site_directory)

# These look like "/Users/hubbard/code/tgn-whisperer/sites/tgn/docs/2"/episode.mp3
p_dest_mp3=$(dest_dir)/episode.mp3
p_dest_html=$(dest_dir)/episode.html
p_dest_md=$(dest_dir)/episode.md

# and this erases the quote characters
dest_mp3=$(shell echo $(p_dest_mp3))
dest_html=$(shell echo $(p_dest_html))
dest_md=$(shell echo $(p_dest_md))

ep_num=$(shell cat whisperx.json | jq .episode | xargs echo)
podcast=$(shell cat whisperx.json | jq .podcast| xargs echo)


# Declare the target three files and a single target name for manual ops
all: $(dest_mp3) $(dest_html) $(dest_md)

$(dest_mp3): episode.mp3
	cp episode.mp3 $(dest_mp3)

$(dest_html): episode.html
	cp episode.html $(dest_html)

$(dest_md): episode.md
	cp episode.md $(dest_md)

# Now declare how to create them.
episode.mp3:
	@echo Now downloading $(shell pwd)
	cat episode.json | jq .mp3_url | xargs wget -nc --no-use-server-timestamps -O episode.mp3

episode-transcribed.json:
	@echo Now transcribing episode $(ep_num) of $(podcast)
	curl -s -X POST http://axiom.phfactor.net:5050/submit/$(podcast)/$(ep_num) -F file=@episode.mp3 -o episode-transcribed.json --fail --remove-on-error

episode.html:
	-cat episode.json | jq .episode_url | xargs wget -O episode.html --convert-links --retry-on-http-error=429 --wait=5 --random-wait

episode.md: episode-transcribed.json
	python3 ../../../app/episode.py

clean:
	-rm episode.mp3 episode.md episode.html episode-transcribed.json

talk:
	@echo "Running in $(shell pwd)"
	@echo "Running in $(ep_num) from $(podcast)"

